{
  "query": "What is GRPO",
  "timestamp": "2025-12-22T00:48:37.513280",
  "provider": "deepseek",
  "model": "deepseek-v3",
  "response": "Based on the provided context, GRPO stands for **Group Relative Policy Optimization**. It is a method used in reinforcement learning (RL) to reduce training costs by eliminating the need for a separate critic model. Instead, it estimates the baseline from group scores by sampling multiple outputs from the old policy and optimizing the policy model accordingly.\n\n<answer>GRPO stands for Group Relative Policy Optimization, a reinforcement learning technique that reduces training costs by using group scores instead of a critic model to estimate baselines.</answer>",
  "context": [
    {
      "text": "Group Relative Policy Optimization In order to save the training costs of RL, we adopt Group Relative Policy Optimization (GRPO) (Shao et al., 2024), which foregoes the critic model that is typically the same size as the policy model, and estimates the baseline from group scores instead. Specifically, for each question ğ‘, GRPO samples a group of outputs {ğ‘œ1, ğ‘œ2, Â· Â· Â· , ğ‘œğº} from the old policy ğœ‹ğœƒğ‘œğ‘™ğ‘‘ and then optimizes the policy model ğœ‹ğœƒ by maximizing the following objective:",
      "score": 0.23180031776428223,
      "metadata": {
        "source": "DeepSeek.pdf",
        "page": "5",
        "chunk": 133,
        "total_chunks": 460,
        "page_range": "5",
        "embedding_provider": "huggingface",
        "embedding_model": "sentence-transformers/all-mpnet-base-v2",
        "embedding_timestamp": "2025-02-14T22:56:08.940325"
      }
    },
    {
      "text": "A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>. User: prompt. Assistant:",
      "score": 0.12676094472408295,
      "metadata": {
        "source": "DeepSeek.pdf",
        "page": "6",
        "chunk": 162,
        "total_chunks": 460,
        "page_range": "6",
        "embedding_provider": "huggingface",
        "embedding_model": "sentence-transformers/all-mpnet-base-v2",
        "embedding_timestamp": "2025-02-14T22:56:09.155617"
      }
    }
  ]
}